{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f626bd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import math\n",
    "import csv\n",
    "from statistics import mean, median, pstdev\n",
    "\n",
    "WORD_RE = re.compile(r\"[A-Za-z]+(?:'[A-Za-z]+)?|\\d+\")\n",
    "\n",
    "# Frasi: split semplice su . ! ? (non perfetto, ma utile come proxy)\n",
    "SENT_SPLIT_RE = re.compile(r\"[.!?]+\")\n",
    "\n",
    "def count_words(text: str) -> int:\n",
    "    \"\"\"\n",
    "    Conta 'parole' in modo robusto:\n",
    "    - sequenze di lettere (gestisce apostrofi tipo don't)\n",
    "    - numeri (es. 1807)\n",
    "    Perché: split() sbaglia facilmente con punteggiatura e trattini.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return 0\n",
    "    return len(WORD_RE.findall(text))\n",
    "\n",
    "def count_sentences(text: str) -> int:\n",
    "    \"\"\"\n",
    "    Conta frasi in modo semplice: separa per . ! ?\n",
    "    Perché: utile come metrica extra, senza dipendenze esterne.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return 0\n",
    "    parts = [p.strip() for p in SENT_SPLIT_RE.split(text) if p.strip()]\n",
    "    return len(parts)\n",
    "\n",
    "def percentile(sorted_values, p: float):\n",
    "    \"\"\"\n",
    "    Percentile con interpolazione lineare.\n",
    "    sorted_values: lista già ordinata\n",
    "    p: percentile in [0, 100]\n",
    "    Perché: vedere la 'coda' (p90/p95/p99) spesso è più informativo della media.\n",
    "    \"\"\"\n",
    "    if not sorted_values:\n",
    "        return None\n",
    "    if p <= 0:\n",
    "        return sorted_values[0]\n",
    "    if p >= 100:\n",
    "        return sorted_values[-1]\n",
    "\n",
    "    k = (len(sorted_values) - 1) * (p / 100.0)\n",
    "    f = math.floor(k)\n",
    "    c = math.ceil(k)\n",
    "    if f == c:\n",
    "        return sorted_values[int(k)]\n",
    "    d0 = sorted_values[f] * (c - k)\n",
    "    d1 = sorted_values[c] * (k - f)\n",
    "    return d0 + d1\n",
    "\n",
    "def summarize_lengths(lengths):\n",
    "    \"\"\"\n",
    "    Calcola un set di statistiche descrittive.\n",
    "    Uso pstdev (deviazione standard 'popolazione') perché stai descrivendo\n",
    "    l'intero dataset, non stimando da un campione.\n",
    "    \"\"\"\n",
    "    if not lengths:\n",
    "        return {}\n",
    "\n",
    "    lengths_sorted = sorted(lengths)\n",
    "    return {\n",
    "        \"count\": len(lengths_sorted),\n",
    "        \"min\": lengths_sorted[0],\n",
    "        \"max\": lengths_sorted[-1],\n",
    "        \"mean\": mean(lengths_sorted),\n",
    "        \"median\": median(lengths_sorted),\n",
    "        \"std\": pstdev(lengths_sorted),\n",
    "        \"p10\": percentile(lengths_sorted, 10),\n",
    "        \"p25\": percentile(lengths_sorted, 25),\n",
    "        \"p75\": percentile(lengths_sorted, 75),\n",
    "        \"p90\": percentile(lengths_sorted, 90),\n",
    "        \"p95\": percentile(lengths_sorted, 95),\n",
    "        \"p99\": percentile(lengths_sorted, 99),\n",
    "    }\n",
    "\n",
    "def load_json_any_shape(path: str):\n",
    "    \"\"\"\n",
    "    Gestisce due formati comuni:\n",
    "    1) JSON array: [ {...}, {...}, ... ]\n",
    "    2) JSON lines: una riga = un oggetto JSON\n",
    "    Perché: molti dataset grandi sono in JSONL.\n",
    "    \"\"\"\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read().strip()\n",
    "\n",
    "    if not content:\n",
    "        return []\n",
    "\n",
    "    # Provo prima come JSON \"normale\"\n",
    "    try:\n",
    "        data = json.loads(content)\n",
    "        if isinstance(data, list):\n",
    "            return data\n",
    "        # se è un singolo oggetto, lo metto in lista\n",
    "        if isinstance(data, dict):\n",
    "            return [data]\n",
    "    except json.JSONDecodeError:\n",
    "        pass\n",
    "\n",
    "    # Fallback: JSON Lines\n",
    "    items = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            items.append(json.loads(line))\n",
    "    return items\n",
    "\n",
    "def main(json_path: str, save_csv_path: str | None = None, top_n: int = 5):\n",
    "    data = load_json_any_shape(json_path)\n",
    "\n",
    "    rows = []\n",
    "    for obj in data:\n",
    "        context = obj.get(\"context\", \"\")\n",
    "        para_id = obj.get(\"para_id\", \"\")\n",
    "        w = count_words(context)\n",
    "        ch = len(context) if context else 0\n",
    "        s = count_sentences(context)\n",
    "        rows.append({\n",
    "            \"para_id\": para_id,\n",
    "            \"words\": w,\n",
    "            \"chars\": ch,\n",
    "            \"sentences\": s,\n",
    "        })\n",
    "\n",
    "    word_lengths = [r[\"words\"] for r in rows]\n",
    "    char_lengths = [r[\"chars\"] for r in rows]\n",
    "    sent_counts = [r[\"sentences\"] for r in rows]\n",
    "\n",
    "    word_stats = summarize_lengths(word_lengths)\n",
    "    char_stats = summarize_lengths(char_lengths)\n",
    "    sent_stats = summarize_lengths(sent_counts)\n",
    "\n",
    "    print(\"\\n=== STATISTICHE SU context ===\")\n",
    "    print(f\"File: {json_path}\")\n",
    "    print(\"\\n--- Parole (words) ---\")\n",
    "    for k, v in word_stats.items():\n",
    "        print(f\"{k:>6}: {v:.2f}\" if isinstance(v, float) else f\"{k:>6}: {v}\")\n",
    "\n",
    "    print(\"\\n--- Caratteri (chars) ---\")\n",
    "    for k, v in char_stats.items():\n",
    "        print(f\"{k:>6}: {v:.2f}\" if isinstance(v, float) else f\"{k:>6}: {v}\")\n",
    "\n",
    "    print(\"\\n--- Frasi (sentences) ---\")\n",
    "    for k, v in sent_stats.items():\n",
    "        print(f\"{k:>6}: {v:.2f}\" if isinstance(v, float) else f\"{k:>6}: {v}\")\n",
    "\n",
    "    # Top N più lunghi/corti per parole (utile per ispezione)\n",
    "    rows_sorted = sorted(rows, key=lambda r: r[\"words\"])\n",
    "    print(f\"\\n--- Top {top_n} più corti (per parole) ---\")\n",
    "    for r in rows_sorted[:top_n]:\n",
    "        print(f\"{r['para_id']}: {r['words']} parole\")\n",
    "\n",
    "    print(f\"\\n--- Top {top_n} più lunghi (per parole) ---\")\n",
    "    for r in rows_sorted[-top_n:][::-1]:\n",
    "        print(f\"{r['para_id']}: {r['words']} parole\")\n",
    "\n",
    "    if save_csv_path:\n",
    "        with open(save_csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=[\"para_id\", \"words\", \"chars\", \"sentences\"])\n",
    "            writer.writeheader()\n",
    "            writer.writerows(rows)\n",
    "        print(f\"\\n[OK] Salvato CSV: {save_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fc5ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== STATISTICHE SU context ===\n",
      "File: /Users/albi/GitHub/f1nder/data/document_collection.json\n",
      "\n",
      "--- Parole (words) ---\n",
      " count: 131921\n",
      "   min: 1\n",
      "   max: 4077\n",
      "  mean: 221.50\n",
      "median: 227\n",
      "   std: 71.16\n",
      "   p10: 185\n",
      "   p25: 210\n",
      "   p75: 238\n",
      "   p90: 246\n",
      "   p95: 251\n",
      "   p99: 281.00\n",
      "\n",
      "--- Caratteri (chars) ---\n",
      " count: 131921\n",
      "   min: 5\n",
      "   max: 27001\n",
      "  mean: 1262.00\n",
      "median: 1289\n",
      "   std: 394.48\n",
      "   p10: 1045\n",
      "   p25: 1188\n",
      "   p75: 1364\n",
      "   p90: 1427\n",
      "   p95: 1466\n",
      "   p99: 1573.00\n",
      "\n",
      "--- Frasi (sentences) ---\n",
      " count: 131921\n",
      "   min: 1\n",
      "   max: 1121\n",
      "  mean: 19.87\n",
      "median: 16\n",
      "   std: 15.46\n",
      "   p10: 8\n",
      "   p25: 11\n",
      "   p75: 25\n",
      "   p90: 36\n",
      "   p95: 45\n",
      "   p99: 69.00\n",
      "\n",
      "--- Top 12 più corti (per parole) ---\n",
      "Michigan_18370308_24: 1 parole\n",
      "California_18581022_15: 2 parole\n",
      "Kentucky_18480527_6: 3 parole\n",
      "Wisconsin_18760817_18: 7 parole\n",
      "Kentucky_18640630_16: 11 parole\n",
      "Missouri_18401003_27: 14 parole\n",
      "Delaware_18761114_19: 17 parole\n",
      "New_Jersey_18550418_34: 22 parole\n",
      "New_Jersey_18570117_41: 22 parole\n",
      "Arkansas_18510129_29: 23 parole\n",
      "Vermont_18801112_32: 23 parole\n",
      "Alaska_19200515_11: 23 parole\n",
      "\n",
      "--- Top 12 più lunghi (per parole) ---\n",
      "Delaware_19000316_3: 4077 parole\n",
      "Utah_18951023_37: 4060 parole\n",
      "Florida_18851009_9: 3873 parole\n",
      "North_Carolina_18530119_21: 3809 parole\n",
      "Indiana_18380623_30: 3745 parole\n",
      "Massachusetts_18501018_25: 3723 parole\n",
      "Tennessee_18740324_22: 3711 parole\n",
      "New_Mexico_18570103_12: 3677 parole\n",
      "Nevada_18691111_9: 3639 parole\n",
      "New_Mexico_18610727_20: 3624 parole\n",
      "Tennessee_18600410_56: 3546 parole\n",
      "North_Carolina_18610313_27: 3512 parole\n",
      "\n",
      "[OK] Salvato CSV: /Users/albi/GitHub/f1nder/artifacts/exploration_analysys/out.csv\n"
     ]
    }
   ],
   "source": [
    "json_path = \"/Users/albi/GitHub/f1nder/data/document_collection.json\"\n",
    "csv_path = \"/Users/albi/GitHub/f1nder/artifacts/exploration_analysis/out.csv\"\n",
    "top_n = 12\n",
    "\n",
    "main(json_path, save_csv_path=csv_path, top_n=top_n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
